# lightning.pytorch==2.3.1
seed_everything: 123
# ckpt_path: null
trainer:
  logger:
    class_path: lightning.pytorch.loggers.WandbLogger
    init_args:
      project: "BERT-Classification"
      save_dir: "./wandb/${trainer.logger.init_args.project}"
      log_model: true
  max_epochs: 10
  default_root_dir: ./lightning_logs/${trainer.logger.init_args.project}
  callbacks:
    - class_path: lightning.pytorch.callbacks.EarlyStopping
      init_args:
        monitor: "val-BinaryF1Score"
        mode: "max"
        patience: 5
    - class_path: lightning.pytorch.callbacks.ModelCheckpoint
      init_args:
        monitor: "val-BinaryF1Score"
        mode: "max"
        save_top_k: 1
        filename: "{epoch}-{val-BinaryF1Score:.3f}"
        verbose: false
    - class_path: callbacks.BertPredictionWriter
      init_args:
        output_dir: "./predictions/${trainer.logger.init_args.project}"
        write_interval: "epoch"
model:
  class_path: models.BertClassification
  init_args:
    vocab_size: 6914
    hidden_size: 1152
    num_hidden_layers: 12
    num_classes: 2
    dropout_rate: 0.2
    optimizer:
      class_path: torch.optim.AdamW
      init_args:
        lr: 1e-5
        weight_decay: 0.0001
data:
  class_path: datasets.v2.CallRecordsV2DataModule
  init_args:
    data_dir: "./data"
    batch_size: 96
    seed: 12
    num_workers: 64
    mlm: true
    mlm_probability: 0.15
    seq_len: 24
    num_bins: 10
    flatten: true
    stride: 6
    adap_thres: 100000000
    return_labels: true
    collator_fn: CallRecordsDataCollatorForClassification
